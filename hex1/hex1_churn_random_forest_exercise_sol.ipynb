{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4f9a44",
   "metadata": {},
   "source": [
    "# üß† Predicting Customer Churn Using Random Forests\n",
    "Welcome to this practical machine learning exercise. In this notebook, you'll develop a solution for predicting customer churn ‚Äî a classic and highly practical problem in economics, management, and business analytics.\n",
    "\n",
    "**Goal:** Apply machine learning to identify customers at risk of leaving (churning), using historical data.\n",
    "\n",
    "Along the way, you'll:\n",
    "- Preprocess data responsibly (avoiding leakage)\n",
    "- Train and evaluate models\n",
    "- Build pipelines for cleaner workflows\n",
    "- Tune models using validation sets\n",
    "- Deploy a final product-ready solution\n",
    "\n",
    "This notebook emphasizes **intuitive understanding**, **real-world practices**, and links to **further resources**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6efa9c-5882-4b42-b50f-a4ab2d49462b",
   "metadata": {},
   "source": [
    "**Note:** Documentation links are provided extensively, to help you, in the following format:\n",
    "  - [üìò StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a09d78-c36f-4a6b-bace-983e2e2108d8",
   "metadata": {},
   "source": [
    "**Note: Whenever you see the ‚úçÔ∏è symbol, it means you must fill in the blanks with your own code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba58bf0-b2e4-4a38-9be0-d3614c4ef242",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 0: Setup\n",
    "\n",
    "Before we begin, we load the core Python libraries used for:\n",
    "- **Data manipulation** (`pandas`, `numpy`)\n",
    "- **Visualization** (`matplotlib`, `seaborn`)\n",
    "- **Modeling and preprocessing** (`sklearn`)\n",
    "\n",
    "We'll also be using the **scikit-learn** machine learning library throughout this notebook ‚Äî make sure to check the documentation links provided at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb394df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and modeling tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7451e1-3a54-4e3f-8bc7-d416d529a1ba",
   "metadata": {},
   "source": [
    "## üìä Step 1: Load the Data\n",
    "\n",
    "The dataset contains customer data from a (fictional) telecom company. Each row is a customer, and each column is an attribute describing that customer‚Äôs usage patterns or account features.\n",
    "\n",
    "You are given a **train set** and a **test set** (pre-split). This setup simulates a situation where you're developing a model using historical data and then testing how well it might generalize to new customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6f94d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code International plan Voice mail plan  \\\n",
       "0    KS             128        415                 No             Yes   \n",
       "1    OH             107        415                 No             Yes   \n",
       "2    NJ             137        415                 No              No   \n",
       "3    OH              84        408                Yes              No   \n",
       "4    OK              75        415                Yes              No   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# ‚úçÔ∏è Load the the training set into df_train and the test set into df_test.\n",
    "df_train = pd.read_csv('churn_train.csv')\n",
    "df_test = pd.read_csv('churn_test.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179da29",
   "metadata": {},
   "source": [
    "## üéØ Step 2: Understand the Problem ‚Äî Classification\n",
    "This is a **binary classification problem**: each customer either **churns** (`Churn = Yes`) or **stays** (`Churn = No`).\n",
    "\n",
    "**Class imbalance:** Only ~14% of customers are churners. This will affect how we train and evaluate the model.\n",
    "\n",
    "üìå We'll address this through evaluation metrics like precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afafe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# ‚úçÔ∏è Split df_train into X_train and y_train; do the same for df_test.\n",
    "X_train = df_train.drop(\"Churn\", axis=1)\n",
    "y_train = df_train[\"Churn\"]\n",
    "\n",
    "X_test = df_test.drop(\"Churn\", axis=1)\n",
    "y_test = df_test[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c87e08-9b46-489e-a602-6c041dcfa375",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Preprocessing ‚Äî Manual (Leakage-Free)\n",
    "\n",
    "Preprocessing is where most real-world ML effort goes. We must:\n",
    "1. Encode **categorical** features numerically (for the model).\n",
    "2. Scale **numerical** features to help model convergence.\n",
    "3. Avoid **data leakage**: Never use information from the test set to preprocess the training set!\n",
    "\n",
    "üìå We'll handle categorical and numeric features **separately** and then combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5337f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "# ‚úçÔ∏è Create a list variable named categorical_features, containing the names of all categorical feature columns.\n",
    "# ‚úçÔ∏è Create a list variable named numeric_features, containing the names of all numeric feature columns.\n",
    "categorical_features = [\"State\", \"Area code\", \"International plan\", \"Voice mail plan\"]\n",
    "numeric_features = [col for col in X_train.columns if col not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9987f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual preprocessing\n",
    "# ‚úçÔ∏è Fit a OneHotEncoder to the training set, but apply it to both the training and test set!\n",
    "# üí° Hint: Recall the difference between the `fit`, `transform` and `fit_transform` methods.\n",
    "# ‚ùó Important! Use `sparse=False` or `sparse_output=False` (depending on the version of sklearn you're using)\n",
    "# when initializing your OneHotEncoder! It will be important later!\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "ohe.fit(X_train[categorical_features])\n",
    "X_train_cat = ohe.transform(X_train[categorical_features])\n",
    "X_test_cat = ohe.transform(X_test[categorical_features])\n",
    "\n",
    "# ‚úçÔ∏è Now fit a StandardScaler to the training set, but apply it to both the training and test set!\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric_features])\n",
    "X_train_num = scaler.transform(X_train[numeric_features])\n",
    "X_test_num = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6090c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now combine the numerical and categorical features:\n",
    "# ‚ÑπÔ∏è This wouldn't have worked without `sparse=False`!\n",
    "X_train_final = np.hstack([X_train_num, X_train_cat])\n",
    "X_test_final = np.hstack([X_test_num, X_test_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a93cd-b574-4fc2-84c4-65f181d24109",
   "metadata": {},
   "source": [
    "üéì **Why this matters**:\n",
    "\n",
    "- **StandardScaler** rescales features to mean 0 and standard deviation 1, making tree-based models faster and more robust.\n",
    "  - [üìò StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "- **OneHotEncoder** converts categorical variables into binary vectors.\n",
    "  - [üìò OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "‚úçÔ∏è **Your Turn**: Combine the categorical and numeric processed arrays with `np.hstack(...)` to get `X_train_final` and `X_test_final`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b376e2e-6416-4169-97b7-a3357a060f4a",
   "metadata": {},
   "source": [
    "## üå≤ Step 4: Random Forest Training\n",
    "\n",
    "**Random Forests** are one of the most versatile and powerful classifiers, especially for tabular data.\n",
    "\n",
    "They are:\n",
    "- **Ensemble models** made of many decision trees.\n",
    "- Resistant to overfitting thanks to randomness.\n",
    "- Handle both categorical (after encoding) and numeric features well.\n",
    "\n",
    "[üìò RandomForestClassifier Docs](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6247024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "# ‚úçÔ∏è Create a new RandomForestClassifier and assign it the a variable named `model`.\n",
    "# ‚úçÔ∏è Fit your RandomForestClassifier in the training set.\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802c250-cf8c-405a-a78c-abeaca4e0a54",
   "metadata": {},
   "source": [
    "## üìä Step 5: Evaluation on Held-Out Test Set\n",
    "\n",
    "To estimate how well your model might perform in production, use a **test set that the model hasn‚Äôt seen**.\n",
    "\n",
    "Use:\n",
    "- [üìò accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [üìò classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "\n",
    "üìå **Reminder**: With class imbalance, accuracy can be misleading. Look at **precision, recall, and F1 score** as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d74ea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9445277361319341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.97       572\n",
      "        True       0.95      0.64      0.77        95\n",
      "\n",
      "    accuracy                           0.94       667\n",
      "   macro avg       0.95      0.82      0.87       667\n",
      "weighted avg       0.94      0.94      0.94       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "# ‚úçÔ∏è Save the prediction of your model on the test set to `y_pred`.\n",
    "y_pred = model.predict(X_test_final)\n",
    "# ‚úçÔ∏è Print the accuracy score your model got.\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# ‚úçÔ∏è Print a classification report for your model.\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7813b-5da5-43b2-8e69-aafa9888fd26",
   "metadata": {},
   "source": [
    "## üîÅ Step 6: Use Pipelines\n",
    "\n",
    "Manual preprocessing is error-prone. Use [üìò Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to:\n",
    "\n",
    "- Bundle preprocessing and modeling together.\n",
    "- Reduce leakage risk.\n",
    "- Improve reproducibility.\n",
    "\n",
    "We'll use [üìò ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to apply different preprocessing to numeric and categorical features.\n",
    "\n",
    "üìö Read more:\n",
    "- [üìò sklearn Pipelines Tutorial](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- [üìù Blog Post](https://towardsdatascience.com/how-to-use-columntransformer-for-numerical-and-categorical-data-6d8cbd25f4b6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b41ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.97       572\n",
      "        True       0.95      0.64      0.77        95\n",
      "\n",
      "    accuracy                           0.94       667\n",
      "   macro avg       0.95      0.82      0.87       667\n",
      "weighted avg       0.94      0.94      0.94       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn pipeline\n",
    "# ‚úçÔ∏è Create a ColumnTransformer object, made up of a StandardScaler followed by a OneHotEncoder object.\n",
    "#‚ùó Important! Remember to use `sparse=False` or `sparse_output=False`.\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)\n",
    "])\n",
    "\n",
    "# ‚úçÔ∏è Now create a Pipeline object made up of your column transformer object and a RandomForestClassifier object.\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ‚úçÔ∏è Fit your pipeline object on the training set, then predict results for the test set\n",
    "# and produce a classification report.\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea32585-1822-4f94-a0fa-16938544de12",
   "metadata": {},
   "source": [
    "## üîç Step 7: Manual Hyperparameter Tuning\n",
    "\n",
    "To make better models, tune key hyperparameters. We‚Äôll try different values for `max_depth`.\n",
    "\n",
    "We'll use a **train-validation-test** split:\n",
    "- **Train**: build models\n",
    "- **Validation**: compare models\n",
    "- **Test**: final performance estimate\n",
    "\n",
    "[üìò train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9426854-68c6-4ce4-958d-1c13d3f0b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's unite the training and validation sets into one big set:\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X = df_full.drop(\"Churn\", axis=1)\n",
    "y = df_full[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9540e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split for tuning\n",
    "# We use train_test_split to get a three-way split: Firstg into trainval and test;\n",
    "# then we split trainval into train and validation.\n",
    "X_trainval, X_test_final, y_trainval, y_test_final = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42, stratify=y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f8e0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      1.00      0.93       570\n",
      "        True       0.93      0.14      0.25        97\n",
      "\n",
      "    accuracy                           0.87       667\n",
      "   macro avg       0.90      0.57      0.59       667\n",
      "weighted avg       0.88      0.87      0.83       667\n",
      "\n",
      "----------------------------------------\n",
      "Max Depth: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96       570\n",
      "        True       0.96      0.52      0.67        97\n",
      "\n",
      "    accuracy                           0.93       667\n",
      "   macro avg       0.94      0.76      0.81       667\n",
      "weighted avg       0.93      0.93      0.92       667\n",
      "\n",
      "----------------------------------------\n",
      "Max Depth: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      1.00      0.97       570\n",
      "        True       0.98      0.64      0.77        97\n",
      "\n",
      "    accuracy                           0.95       667\n",
      "   macro avg       0.96      0.82      0.87       667\n",
      "weighted avg       0.95      0.95      0.94       667\n",
      "\n",
      "----------------------------------------\n",
      "Max Depth: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.97       570\n",
      "        True       0.94      0.64      0.76        97\n",
      "\n",
      "    accuracy                           0.94       667\n",
      "   macro avg       0.94      0.82      0.86       667\n",
      "weighted avg       0.94      0.94      0.94       667\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Manual hyperparameter tuning\n",
    "# ‚úçÔ∏è Manually find the best value for the max_depth hyperparameter out of [5, 10, 15, 20]:\n",
    "# üí° Hint: Use a for loop to iterate over a list of possible values. Then, for each such value,\n",
    "# create a new pipeline with the appropriate value for RandomForestClassifier (you DON'T have to\n",
    "# create your ColumnTransformer again; use the same object you've already created), fit it on the\n",
    "# training set and evaluate it on the **validation set**! Do NOT touch the test set in this loop!\n",
    "\n",
    "depths = [5, 10, 20, None]\n",
    "for d in depths:\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('rf', RandomForestClassifier(max_depth=d, random_state=42))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    val_preds = pipeline.predict(X_val)\n",
    "    print(f\"Max Depth: {d}\")\n",
    "    print(classification_report(y_val, val_preds))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f43ee-f6b1-42b1-8c3f-cb27ed56ac08",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 8: Final Evaluation and Deployment-Ready Model\n",
    "\n",
    "After choosing the best hyperparameter from the validation set, retrain your model on **train+val** and evaluate on **test**.\n",
    "\n",
    "Then, retrain a final version on **all labeled data** to use in production.\n",
    "\n",
    "You can save the model for future use using:\n",
    "[üìò sklearn model persistence](https://scikit-learn.org/stable/model_persistence.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6c4cf-0a25-4c4b-8b1f-d09422ebfbf4",
   "metadata": {},
   "source": [
    "### 8.1: Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f533c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      1.00      0.95       570\n",
      "        True       0.98      0.43      0.60        97\n",
      "\n",
      "    accuracy                           0.92       667\n",
      "   macro avg       0.94      0.72      0.78       667\n",
      "weighted avg       0.92      0.92      0.90       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final model evaluation\n",
    "# ‚úçÔ∏è Now create the pipeline again, now with max_depth set to the value which showed the\n",
    "# best results. Then, fit it on the **X_trainval** set, and predict on the test set.\n",
    "# What is the model performance? That's our estimate for future performamce.\n",
    "best_depth = 10  # Replace with chosen value\n",
    "pipeline_final = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('rf', RandomForestClassifier(max_depth=best_depth, random_state=42))\n",
    "])\n",
    "pipeline_final.fit(X_trainval, y_trainval)\n",
    "test_preds = pipeline_final.predict(X_test_final)\n",
    "print(classification_report(y_test_final, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd229a26-c1c1-44b5-bee1-ca62333a908d",
   "metadata": {},
   "source": [
    "### üí¨ Answer the following questions:\n",
    "- Are there more false positives or false negatives?\n",
    "- Which mistake is more costly in your business scenario?\n",
    "- Should you tune the model to favor precision or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23b69b-348f-4edf-ad33-6443003be3a6",
   "metadata": {},
   "source": [
    "### üß™ Sub-Task: Plot the Confusion Matrix\n",
    "\n",
    "The **confusion matrix** helps you visually assess where your model is getting things right or wrong.\n",
    "\n",
    "It breaks predictions into:\n",
    "- **True Positives (TP)**: correctly predicted churners.\n",
    "- **True Negatives (TN)**: correctly predicted non-churners.\n",
    "- **False Positives (FP)**: predicted churn but customer stayed.\n",
    "- **False Negatives (FN)**: predicted stay but customer churned.\n",
    "\n",
    "This can help you **understand your model's trade-offs**, especially when classifying rare events (like churn).\n",
    "\n",
    "üìò Documentation:\n",
    "- [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "- [sklearn.metrics.ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)\n",
    "\n",
    "‚úçÔ∏è **Your task**: Use `ConfusionMatrixDisplay.from_predictions(...)` to plot the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b58c1638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x10f34dc30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_final, test_preds,\n",
    "    display_labels=[\"No Churn\", \"Churn\"],\n",
    "    cmap=\"Blues\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bb79c-4c92-484f-b69f-1e8691bb4671",
   "metadata": {},
   "source": [
    "### 8.2: Train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b38234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['Account length',\n",
       "                                                   'Number vmail messages',\n",
       "                                                   'Total day minutes',\n",
       "                                                   'Total day calls',\n",
       "                                                   'Total day charge',\n",
       "                                                   'Total eve minutes',\n",
       "                                                   'Total eve calls',\n",
       "                                                   'Total eve charge',\n",
       "                                                   'Total night minutes',\n",
       "                                                   'Total night calls',\n",
       "                                                   'Total night charge',\n",
       "                                                   'Total intl minutes',\n",
       "                                                   'Total intl calls',\n",
       "                                                   'Total intl charge',\n",
       "                                                   'Customer service calls']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['State', 'Area code',\n",
       "                                                   'International plan',\n",
       "                                                   'Voice mail plan'])])),\n",
       "                ('rf', RandomForestClassifier(max_depth=10, random_state=42))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final product-ready model\n",
    "# ‚úçÔ∏è Now create the pipeline again, one last time. Fit it on the entire dataset (X and y variables).\n",
    "# That's it! You're done! Great job!\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('rf', RandomForestClassifier(max_depth=best_depth, random_state=42))\n",
    "])\n",
    "final_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f213926-3609-4877-8fa2-1d3b50b1f6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

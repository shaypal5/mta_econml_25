
# ğŸ’³ Detecting Financial Fraud with Machine Learning

Welcome! In this module, you'll take on the role of a data scientist working to detect fraud in mobile money transactions. Fraud is rare, but costly â€” and catching it requires more than just good accuracy. We'll walk through a full machine learning workflow using a realistic, imbalanced dataset and modern tools.

---

## ğŸ“š Learning Goals

By the end of this session, you will be able to:

- âœ… Explain why class imbalance is a common and critical issue in real-world decision-making.
- ğŸ” Evaluate classification models with appropriate metrics (e.g., precision, recall, ROC-AUC).
- ğŸ§ª Apply techniques like SMOTE and ensemble models to improve detection of rare events.
- ğŸ“ˆ Understand the role of score calibration and probability thresholds in business decisions.
- ğŸ’¼ Design a fraud detection policy that reflects resource constraints and cost trade-offs.

---

## ğŸ—‚ï¸ Project Structure

| File | Description |
|------|-------------|
| `data/imbl_fraud.csv` | Pre-sampled PaySim dataset (fraud rate ~6%) |
| `notebooks/01_baseline_model_ex.ipynb` | ğŸ“ Exercise â€“ EDA + baseline model with metrics |
| `notebooks/01_baseline_model_sol.ipynb` | âœ… Solution â€“ EDA + baseline model completed |
| `notebooks/02_imbalance_handling_ex.ipynb` | ğŸ“ Exercise â€“ SMOTE + balanced ensemble models |
| `notebooks/02_imbalance_handling_sol.ipynb` | âœ… Solution â€“ SMOTE + balanced ensemble models |
| `notebooks/03_calibration_thresholds_ex.ipynb` | ğŸ“ Exercise â€“ Score calibration, top-k targeting |
| `notebooks/03_calibration_thresholds_sol.ipynb` | âœ… Solution â€“ Score calibration, top-k targeting |
| `notebooks/04_bonus_cost_sensitive_ex.ipynb` | ğŸ“ (Optional) Exercise â€“ Custom thresholds + costs |
| `notebooks/04_bonus_cost_sensitive_sol.ipynb` | âœ… (Optional) Solution â€“ Custom thresholds + costs |
| `utils/metrics_helpers.py` | Reusable functions: PR@k, calibration plot, confusion matrix |
| `activities/decision_policy_prompt.md` | In-class discussion prompt: How would *you* deploy a model? |
| `problem_generation/` | Code to generate the imbalanced dataset (you can ignore it) |


---

## ğŸ¥ Slides

ğŸ“½ï¸ **[Intro Slides â€” Real-World Fraud Detection & Class Imbalance](https://your-slides-link.com)**  
*(Make a copy in your Google Drive if you'd like to take notes.)*

---

## ğŸš€ Getting Started

You can run this project on your local machine or in Google Colab.

### Option 1: Jupyter Lab
If you have Jupyter set up:

```bash
jupyter lab
```

Then open any notebook inside the `notebooks/` folder.

### Option 2: Google Colab
Just drag and drop a notebook into [Google Colab](https://colab.research.google.com/), then upload `data/imbl_fraud.csv` when prompted.

---

## ğŸ’¡ Tips

- The dataset is **imbalanced** â€” don't trust accuracy!
- Focus on **recall** if you're trying to catch as much fraud as possible.
- Focus on **precision** if investigations are costly and you want fewer false alarms.
- Thereâ€™s no single "best" threshold â€” it depends on your business case.

---

## ğŸ› ï¸ Tools & Libraries

- `pandas`, `matplotlib`, `seaborn`
- `scikit-learn`
- `imbalanced-learn` (for SMOTE, balanced models)

No environment file needed â€” just make sure these are installed, or use Colab.

---

## ğŸ“„ License

MIT â€” feel free to remix and reuse this for your own learning or teaching.

---

ğŸ‘©â€ğŸ« Developed for an Intro to Machine Learning course (Econ & Management undergraduate level).
